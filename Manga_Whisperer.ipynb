{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTaAWEa8Jcgq"
      },
      "source": [
        "# Manga_Whisperer\n",
        "\n",
        "<br>Generate a transcript for your favourite Manga: Detect manga characters, text blocks and panels. Order panels. Cluster characters. Match texts to their speakers. Perform OCR.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Manga Upscaler { display-mode: \"form\" }\n",
        "# !pip install rarfile\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from huggingface_hub import HfApi, snapshot_download, create_repo\n",
        "import zipfile\n",
        "# import rarfile\n",
        "\n",
        "# Token Hugging Face (zastąp swoim aktualnym tokenem)\n",
        "hf_token = \"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\"\n",
        "\n",
        "# Inicjalizacja API\n",
        "api = HfApi()\n",
        "\n",
        "# Nazwa datasetu\n",
        "dataset_name = \"MattyMroz/image_working_space\"\n",
        "\n",
        "# Ścieżka do lokalnego katalogu, gdzie jest przechowywany dataset\n",
        "local_dir = \"/kaggle/working/image_working_space\"\n",
        "\n",
        "\n",
        "def ensure_repo_exists():\n",
        "    try:\n",
        "        api.repo_info(repo_id=dataset_name, repo_type=\"dataset\")\n",
        "        print(f\"Repozytorium {dataset_name} istnieje.\")\n",
        "    except Exception:\n",
        "        print(f\"Repozytorium {dataset_name} nie istnieje. Tworzę nowe...\")\n",
        "        create_repo(repo_id=dataset_name, repo_type=\"dataset\", token=hf_token)\n",
        "        print(f\"Repozytorium {dataset_name} zostało utworzone.\")\n",
        "\n",
        "    if not os.path.exists(local_dir):\n",
        "        print(\"Pobieram zawartość repozytorium...\")\n",
        "        snapshot_download(repo_id=dataset_name, local_dir=local_dir,\n",
        "                          repo_type=\"dataset\", token=hf_token)\n",
        "        print(\"Zawartość repozytorium została pobrana.\")\n",
        "\n",
        "\n",
        "def push_changes_to_hub():\n",
        "    try:\n",
        "        api.upload_folder(\n",
        "            folder_path=local_dir,\n",
        "            repo_id=dataset_name,\n",
        "            repo_type=\"dataset\",\n",
        "            token=hf_token,\n",
        "            ignore_patterns=[\"*.pyc\", \".DS_Store\", \".gitignore\"],\n",
        "            delete_patterns=[\"*\"]\n",
        "        )\n",
        "        print(\"Zmiany zostały wysłane do Hugging Face.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Błąd podczas wysyłania zmian: {e}\")\n",
        "\n",
        "\n",
        "def check_clone_huggingface_output_repo():\n",
        "    if not os.path.exists(\"/kaggle/working/image_working_space\"):\n",
        "        print(\"Pobieranie image_working_space z Hugging Face...\")\n",
        "        ensure_repo_exists()\n",
        "\n",
        "\n",
        "def check_clone_manga_whisperer_repo():\n",
        "    if not os.path.exists(\"/kaggle/working/Manga_Whisperer\"):\n",
        "        print(\"Pobieranie Manga_Whisperer...\")\n",
        "        subprocess.run(\n",
        "            [\"git\", \"clone\", \"https://github.com/MattyMroz/Manga_Whisperer.git\"])\n",
        "        print(\"Instalowanie wymaganych pakietów...\")\n",
        "        subprocess.run([\"pip\", \"install\", \"-r\", \"/kaggle/working/Manga_Whisperer/requirements.txt\"])\n",
        "\n",
        "\n",
        "def init_dirs():\n",
        "    input_dir = Path(\"/kaggle/working/image_working_space/input\")\n",
        "    transcription_dir = Path(\n",
        "        \"/kaggle/working/image_working_space/transcription\")\n",
        "    transcription_images_dir = Path(\n",
        "        \"/kaggle/working/image_working_space/transcription_images\")\n",
        "\n",
        "    input_dir.mkdir(parents=True, exist_ok=True)\n",
        "    transcription_dir.mkdir(parents=True, exist_ok=True)\n",
        "    transcription_images_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    (input_dir / \"README.md\").write_text(\"Umieść tutaj obrazy do transkrypcji.\")\n",
        "    (transcription_dir / \"README.md\").write_text(\"Tutaj pojawią się transkrypcje.\")\n",
        "    (transcription_images_dir /\n",
        "     \"README.md\").write_text(\"Tutaj pojawią się obrazy z wizualizacją transkrypcji.\")\n",
        "\n",
        "\n",
        "def dir_contains_files(path):\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        if files:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def extract_archives():\n",
        "    input_dir = Path(\"/kaggle/working/image_working_space/input\")\n",
        "    for file in input_dir.iterdir():\n",
        "        if file.suffix.lower() == \".zip\":\n",
        "            with zipfile.ZipFile(file, 'r') as zip_ref:\n",
        "                zip_ref.extractall(input_dir)\n",
        "            print(f\"Wypakowano {file}\")\n",
        "        # elif file.suffix.lower() == \".rar\":\n",
        "        #     with rarfile.RarFile(file, 'r') as rar_ref:\n",
        "        #         rar_ref.extractall(input_dir)\n",
        "        #     print(f\"Wypakowano {file}\")\n",
        "\n",
        "\n",
        "def transcribe_manga():\n",
        "    subprocess.run([\n",
        "        \"python\", \"/kaggle/working/Manga_Whisperer/manga_transcriber.py\",\n",
        "        \"-i\", \"/kaggle/working/image_working_space/input\",\n",
        "        \"-t\", \"/kaggle/working/image_working_space/transcription\",\n",
        "        \"-ti\", \"/kaggle/working/image_working_space/transcription_images\",\n",
        "        \"-se\"\n",
        "    ])\n",
        "\n",
        "\n",
        "def zip_output():\n",
        "    transcription_dir = Path(\n",
        "        \"/kaggle/working/image_working_space/transcription\")\n",
        "    transcription_images_dir = Path(\n",
        "        \"/kaggle/working/image_working_space/transcription_images\")\n",
        "    zip_dir = Path(\"/kaggle/working/image_working_space/zip\")\n",
        "\n",
        "    zip_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Zipowanie folderu transcription\n",
        "    transcription_zip_path = zip_dir / \"transcription.zip\"\n",
        "    with zipfile.ZipFile(transcription_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(transcription_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, transcription_dir)\n",
        "                zipf.write(file_path, arcname)\n",
        "    print(\n",
        "        f\"Zawartość folderu transcription została spakowana do {transcription_zip_path}\")\n",
        "\n",
        "    # Zipowanie folderu transcription_images\n",
        "    transcription_images_zip_path = zip_dir / \"transcription_images.zip\"\n",
        "    with zipfile.ZipFile(transcription_images_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(transcription_images_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, transcription_images_dir)\n",
        "                zipf.write(file_path, arcname)\n",
        "    print(\n",
        "        f\"Zawartość folderu transcription_images została spakowana do {transcription_images_zip_path}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Manga Transcriber\")\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"Ta sesja nie ma dostępu do GPU.\\nAby połączyć się z GPU, kliknij:\\n'Settings' -> 'Accelerator' -> 'GPU T4 x2'.\\nNastępnie uruchom ten skrypt ponownie.\")\n",
        "        return\n",
        "\n",
        "    check_clone_huggingface_output_repo()\n",
        "    check_clone_manga_whisperer_repo()\n",
        "    init_dirs()\n",
        "\n",
        "    status = 0\n",
        "    if dir_contains_files(\"/kaggle/working/image_working_space/input\"):\n",
        "        extract_archives()\n",
        "        status += 1\n",
        "        print(\"Transkrybowanie mangi...\")\n",
        "        transcribe_manga()\n",
        "        push_changes_to_hub()\n",
        "\n",
        "    if status == 0:\n",
        "        print(\"Nie znaleziono obrazów do przetworzenia w /kaggle/working/image_working_space/input\")\n",
        "    else:\n",
        "        print(\"Przetwarzanie zostało zakończone\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def tree(directory):\n",
        "    output = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        level = root.replace(directory, '').count(os.sep)\n",
        "        indent = '&nbsp;&nbsp;&nbsp;&nbsp;' * level\n",
        "        output.append(f'{indent}<span style=\"color: blue;\">{os.path.basename(root)}/</span><br>')\n",
        "        subindent = '&nbsp;&nbsp;&nbsp;&nbsp;' * (level + 1)\n",
        "        for f in files:\n",
        "            output.append(f'{subindent}<span style=\"color: green;\">{f}</span><br>')\n",
        "    return ''.join(output)\n",
        "\n",
        "# Użyj tej funkcji dla wybranego katalogu, np. /kaggle\n",
        "html_tree = tree('/kaggle')\n",
        "display(HTML(f'<pre style=\"line-height: 1.2;\">{html_tree}</pre>'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
